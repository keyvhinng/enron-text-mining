{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./mails_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42638, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-14 23:39:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'tim.belden@enron.com'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is our forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-04 20:51:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'john.lavorato@enron.com'}</td>\n",
       "      <td>Re:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-18 10:00:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'leah.arsdall@enron.com'}</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-23 13:13:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'randall.gay@enron.com'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy,   Can you send me a schedule of the sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-08-31 12:07:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'greg.piper@enron.com'}</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      file  \\\n",
       "0           0     allen-p/_sent_mail/1.   \n",
       "1           1    allen-p/_sent_mail/10.   \n",
       "2           2   allen-p/_sent_mail/100.   \n",
       "3           3  allen-p/_sent_mail/1000.   \n",
       "4           4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                      Message-ID                 Date  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>  2001-05-14 23:39:00   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>  2001-05-04 20:51:00   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>  2000-10-18 10:00:00   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>  2000-10-23 13:13:00   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>  2000-08-31 12:07:00   \n",
       "\n",
       "                          From                           To    Subject X-cc  \\\n",
       "0  {'phillip.allen@enron.com'}     {'tim.belden@enron.com'}        NaN  NaN   \n",
       "1  {'phillip.allen@enron.com'}  {'john.lavorato@enron.com'}        Re:  NaN   \n",
       "2  {'phillip.allen@enron.com'}   {'leah.arsdall@enron.com'}   Re: test  NaN   \n",
       "3  {'phillip.allen@enron.com'}    {'randall.gay@enron.com'}        NaN  NaN   \n",
       "4  {'phillip.allen@enron.com'}     {'greg.piper@enron.com'}  Re: Hello  NaN   \n",
       "\n",
       "  X-bcc                                               body  \n",
       "0   NaN                               Here is our forecast  \n",
       "1   NaN  Traveling to have a business meeting takes the...  \n",
       "2   NaN                     test successful.  way to go!!!  \n",
       "3   NaN  Randy,   Can you send me a schedule of the sal...  \n",
       "4   NaN                  Let's shoot for Tuesday at 11:45.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42454, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-14 23:39:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'tim.belden@enron.com'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is our forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-04 20:51:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'john.lavorato@enron.com'}</td>\n",
       "      <td>Re:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-18 10:00:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'leah.arsdall@enron.com'}</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-23 13:13:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'randall.gay@enron.com'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy,   Can you send me a schedule of the sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-08-31 12:07:00</td>\n",
       "      <td>{'phillip.allen@enron.com'}</td>\n",
       "      <td>{'greg.piper@enron.com'}</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                     Message-ID  \\\n",
       "0     allen-p/_sent_mail/1.  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1    allen-p/_sent_mail/10.  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2   allen-p/_sent_mail/100.  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  allen-p/_sent_mail/1000.  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  allen-p/_sent_mail/1001.  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                  Date                         From  \\\n",
       "0  2001-05-14 23:39:00  {'phillip.allen@enron.com'}   \n",
       "1  2001-05-04 20:51:00  {'phillip.allen@enron.com'}   \n",
       "2  2000-10-18 10:00:00  {'phillip.allen@enron.com'}   \n",
       "3  2000-10-23 13:13:00  {'phillip.allen@enron.com'}   \n",
       "4  2000-08-31 12:07:00  {'phillip.allen@enron.com'}   \n",
       "\n",
       "                            To    Subject X-cc X-bcc  \\\n",
       "0     {'tim.belden@enron.com'}        NaN  NaN   NaN   \n",
       "1  {'john.lavorato@enron.com'}        Re:  NaN   NaN   \n",
       "2   {'leah.arsdall@enron.com'}   Re: test  NaN   NaN   \n",
       "3    {'randall.gay@enron.com'}        NaN  NaN   NaN   \n",
       "4     {'greg.piper@enron.com'}  Re: Hello  NaN   NaN   \n",
       "\n",
       "                                                body  \n",
       "0                               Here is our forecast  \n",
       "1  Traveling to have a business meeting takes the...  \n",
       "2                     test successful.  way to go!!!  \n",
       "3  Randy,   Can you send me a schedule of the sal...  \n",
       "4                  Let's shoot for Tuesday at 11:45.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data=data.set_index('Message-ID')\n",
    "data=data.drop(columns='Unnamed: 0')\n",
    "data=data.dropna(axis=0,subset=['body'],how='any')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_from_mails(message):\n",
    "  mail_addresses = re.findall(r'\\(?[A-Za-z0-9_\\-\\.]+@[A-Za-zb0-9_\\-\\.]+\\.com\\)?',message)\n",
    "  if mail_addresses != []:\n",
    "    for mail_address in mail_addresses:\n",
    "      message=message.replace(mail_address,'').strip()\n",
    "  return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_clean']=data['body'].map(clean_from_mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar palabras con digitos y signos de puntuacion\n",
    "data['body_clean']=data['body_clean'].map(lambda x: ' '.join(re.sub(r'[^a-zA-Z]',' ',x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar todo a minusculas\n",
    "data['body_clean']=data['body_clean'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kref/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords final (208):\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'also', 'please', 'would']\n"
     ]
    }
   ],
   "source": [
    "my_stopwords = stopwords.words('english')\n",
    "# Excluir palabras de una sola letra\n",
    "for i in range(ord('a'),ord('z')+1):\n",
    "  my_stopwords.append(chr(i))\n",
    "# AÃ±adir would\n",
    "my_stopwords = my_stopwords + ['also','please','would']\n",
    "print(f'Stopwords final ({len(my_stopwords)}):')\n",
    "print(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg_stopwords(message_body):\n",
    "    words = message_body.split()\n",
    "    words = [w for w in words if w not in set(my_stopwords)]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_clean']=data.body_clean.apply(clean_msg_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna(axis=0,subset=['body_clean'],how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kref/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = []\n",
    "for doc in data['body_clean']:\n",
    "  word_vector.append(doc.split())\n",
    "my_vocabulary = [item for sublist in word_vector for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'successful', 'way', 'go']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario consta de 4047756 elementos y 44475 palabras diferentes.\n"
     ]
    }
   ],
   "source": [
    "print(f'El vocabulario consta de {len(my_vocabulary)} elementos y {len(set(my_vocabulary))} palabras diferentes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kref/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_body(message_body):\n",
    "  return ' '.join(lemma.lemmatize(word) for word in message_body.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_vector = []\n",
    "for doc in data['body_clean']:\n",
    "  lemma_vector.append(lemmatize_body(doc).split())\n",
    "my_lema_voc = [item for sublist in lemma_vector for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario de lemas consta de 4047756 elementos y 40903 palabras diferentes.\n"
     ]
    }
   ],
   "source": [
    "print(f'El vocabulario de lemas consta de {len(my_lema_voc)} elementos y {len(set(my_lema_voc))} palabras diferentes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_lemma'] = data['body_clean'].map(lemmatize_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test successful way go'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body_lemma'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['body_lemma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = []\n",
    "for doc in data['body_lemma']:\n",
    "  word_vector.append(doc.split())\n",
    "my_vocabulary = [item for sublist in word_vector for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['let', 'shoot', 'tuesday']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similaridad de Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forecast'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id[\"forecast\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dictionary: 40903\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in dictionary:\",len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in word_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=42454, num_nnz=2761697)\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento Similaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kref/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:718: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 42454 documents in 1 shards (stored under ./)\n",
      "<class 'gensim.similarities.docsim.Similarity'>\n"
     ]
    }
   ],
   "source": [
    "sims = gensim.similarities.Similarity('./',tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))\n",
    "print(sims)\n",
    "print(type(sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = [w.lower() for w in word_tokenize(\"duplication of efforts\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_bow = dictionary.doc2bow(query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idf = tf_idf[query_doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_w_index = list(enumerate(sims[query_doc_tf_idf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(reversed(sorted(sim_w_index,key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(41927, 0.22135752),\n",
       " (41732, 0.22135752),\n",
       " (7349, 0.21695684),\n",
       " (5554, 0.21695684),\n",
       " (3848, 0.21695684),\n",
       " (30251, 0.18691298),\n",
       " (35294, 0.17971303),\n",
       " (35402, 0.1345826),\n",
       " (26615, 0.12446223),\n",
       " (25279, 0.12446223)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41927"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0][0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is it really necessary to coordinate everything through ENW?  I am not sure  people will do that?  I think ENW should be informed but not be in control of  the registration.  Have the ENW people requested that they be in charge of  this process?  Will they care if we change it?     Leslie Hansen  12/12/2000 02:14 PM        To: Mark E Haedicke/HOU/ECT@ECT    cc:     Subject: Enron Policy re Use of Third Party Trading Platforms  Mark:  I wanted to follow up to see if you have had an opportunity to consider the  proposed policy attached below.  Currently, the traders have no guidelines  governing their use of third party electronic trading platforms, and there  has been no centralized system for monitoring such use.    Please give me a call with any questions or comments.  Leslie  Enron Policy re Use of Third Party Trading Platforms  Mark:  Mark Taylor and I have worked with Andy Zipper to develop a policy relating  to use of third party electronic trading platforms.  We propose that you and  Mark Frevert send the attached e-mail to all traders informing them of this  policy.  Note that I included a contact for questions at the bottom of the  policy.  I have listed myself for now.  We discussed sending this e-mail to  all Enron traders, including those in Europe and within other business units.  Mark Taylor, Andy Zipper and Sheri Thomas (the designated master user who  currently acts as Product Control Director for EnronOnline) have approved the  e-mail and the policy.  I look forward to your comments on the policy.  After you have approved the  e-mail and the policy, I will coordinate with Andy and Sheri to determine how  best to circulate the e-mail.  Leslie  ************************************************************************** Many of you have received offers to use third -party electronic trading  platforms like Dynegydirect.  Enron has a Policy Relating to Use of Third  Party Electronic Trading Platforms to serve as a guide to appropriate  registration for and use of such trading platforms.  The Policy provides that:  You must notify the Enron Net Works LLC (ENW) designee set out in the Policy  if you would like to trade on such a trading platform. All registration and other documentation must be sent to the ENW designee,  who will coordinate the necessary legal and administrative review. You are not authorized to use a third-party electronic trading platform until  you are authorized by ENW. The Master User for all third-party electronic trading platform accounts will  be an ENW designee. If you are currently using any third-party electronic trading platform,  please notify the ENW designee.  A full copy of the Policy Statement is attached for your review.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body'][x[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
